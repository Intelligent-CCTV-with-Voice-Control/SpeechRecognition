"""Transformer-based seque# Use the smallest model for faster inference and less memory
DEFAULT_MODEL = os.getenv("TRANSFORMER_MODEL", "t5-small") 
MAX_NEW_TOKENS = int(os.getenv("TRANSFORMER_MAX_NEW_TOKENS", "128"))
DEVICE = os.getenv("TRANSFORMER_DEVICE", "cuda")  # Default to CUDA if available-to-sequence entity extractor.

Goal: Convert a natural language playback / camera command into structured
JSON containing entities (date, date_range_start, date_range_end,
start_time, end_time, camera, part_of_day, direction, etc.).

Design:
- Uses a lightweight instruction prompt + the raw text.
- Loads a small seq2seq model by default (T5-small) to balance latency vs accuracy.
- If environment TRANSFORMER_MODEL is set, uses that instead.
- Attempts to parse the model output as JSON (robust to extra text).
- Falls back to empty dict on failure.

NOTE: This is a generic prompt-based approach; accuracy will depend on the
chosen model. For more consistent extraction, fine-tune or craft a better
set of few-shot exemplars.
"""
from __future__ import annotations
import os
import json
from typing import Dict, Any

# Lazy imports so that environments not using transformer backend don't pay cost
_model = None
_tokenizer = None

DEFAULT_MODEL = os.getenv("TRANSFORMER_MODEL", "t5-large")
MAX_NEW_TOKENS = int(os.getenv("TRANSFORMER_MAX_NEW_TOKENS", "128"))
DEVICE = os.getenv("TRANSFORMER_DEVICE", "cuda")  # Default to CUDA if available

INSTRUCTION = (
    "Extract CCTV playback / PTZ entities as compact JSON keys. Allowed keys: "
    "intent, date, date_range_start, date_range_end, start_time, end_time, camera, part_of_day, direction. "
    "Times must be 24h HH:MM. If single time only, put it in start_time. "
    "If a range crosses midnight without explicit next-day phrase, keep given times. "
    "If relative dates (yesterday, today, tomorrow) resolve them to ISO YYYY-MM-DD (assume current locale date). "
    "If multiple relative days appear (e.g. yesterday ... today) set date_range_start and date_range_end to each resolved ISO date. "
    "If camera/channel specified output camera as integer string. "
    "Pay special attention to time formats: 'H-M' format (like '8-1') means '8:01', not '8:30'. "
    "When a hyphen is used between numbers, interpret as hour:minute (8-1 → 08:01, 9-5 → 09:05). "
    "Respond ONLY with minified JSON object, no commentary."
)

EXAMPLES = [
    ("playback camera 2 yesterday from 5 pm to 6 pm", '{"intent":"playback","camera":"2","date":"{YESTERDAY}","date_range_start":"{YESTERDAY}","date_range_end":"{YESTERDAY}","start_time":"17:00","end_time":"18:00"}'),
    ("show playback from 9am to 10am today camera 1", '{"intent":"playback","camera":"1","date":"{TODAY}","date_range_start":"{TODAY}","date_range_end":"{TODAY}","start_time":"09:00","end_time":"10:00"}'),
    ("move camera 3 left", '{"intent":"ptz","camera":"3","direction":"left"}'),
    ("playback from 8 to 8-1 in the morning", '{"intent":"playback","date":"{TODAY}","date_range_start":"{TODAY}","date_range_end":"{TODAY}","start_time":"08:00","end_time":"08:01","part_of_day":"morning"}'),
    ("show camera 1 from 8 to 8-01", '{"intent":"playback","camera":"1","date":"{TODAY}","date_range_start":"{TODAY}","date_range_end":"{TODAY}","start_time":"08:00","end_time":"08:01"}')
]

from datetime import date, timedelta

def _resolve_relatives(example_json: str) -> str:
    today = date.today()
    mapping = {
        '{TODAY}': today.isoformat(),
        '{YESTERDAY}': (today - timedelta(days=1)).isoformat(),
        '{TOMORROW}': (today + timedelta(days=1)).isoformat(),
    }
    for k,v in mapping.items():
        example_json = example_json.replace(k, v)
    return example_json

PROMPT_CACHE = None

def build_prompt(command: str) -> str:
    global PROMPT_CACHE
    if PROMPT_CACHE is None:
        shots = []
        for txt, js in EXAMPLES:
            shots.append(f"Input: {txt}\nOutput: {_resolve_relatives(js)}")
        PROMPT_CACHE = INSTRUCTION + "\n\n" + "\n\n".join(shots) + "\n\n" + "Input: {user}\nOutput:"
    return PROMPT_CACHE.replace('{user}', command)


def load_model():  # pragma: no cover (heavy)
    global _model, _tokenizer
    if _model is not None:
        return _model, _tokenizer
    
    # Determine best device
    actual_device = DEVICE
    try:
        import torch
        if DEVICE == 'cuda' and not torch.cuda.is_available():
            print("[transformer_extractor] CUDA requested but not available, falling back to CPU")
            actual_device = 'cpu'
        elif DEVICE == 'cuda':
            print(f"[transformer_extractor] Using CUDA device: {torch.cuda.get_device_name(0)}")
    except ImportError:
        print("[transformer_extractor] PyTorch not available, using CPU")
        actual_device = 'cpu'
    
    try:
        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
        print(f"[transformer_extractor] Loading {DEFAULT_MODEL} on {actual_device}...")
        _tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL)
        _model = AutoModelForSeq2SeqLM.from_pretrained(DEFAULT_MODEL)
        if actual_device != 'cpu':
            _model = _model.to(actual_device)
            print("[transformer_extractor] Model loaded on GPU")
        else:
            print("[transformer_extractor] Model loaded on CPU")
    except Exception as e:  # pragma: no cover
        print(f"[transformer_extractor] Failed loading model {DEFAULT_MODEL}: {e}")
        _model = None; _tokenizer = None
    
    return _model, _tokenizer


import re

def extract_time_with_regex(text: str) -> Dict[str, Any]:
    """Extract time entities using regex patterns, particularly for hyphenated times."""
    result = {}
    
    # Match patterns like "8 to 8-1" or "8 to 8-01" or "8 to 8:01" 
    time_pattern = r'(\d{1,2})(?:\s+(?:to|until|from)\s+)(\d{1,2})(?:[:-](\d{1,2}))'
    match = re.search(time_pattern, text)
    
    if match:
        start_hour = int(match.group(1))
        end_hour = int(match.group(2))
        end_minute = int(match.group(3))
        
        # Adjust for 24-hour format
        if "pm" in text.lower() and start_hour < 12:
            start_hour += 12
        if "pm" in text.lower() and end_hour < 12:
            end_hour += 12
            
        # Format as HH:MM
        result["start_time"] = f"{start_hour:02d}:00"
        result["end_time"] = f"{end_hour:02d}:{end_minute:02d}"
        
        # Try to detect intent
        if any(word in text.lower() for word in ["playback", "play", "show", "display", "camera"]):
            result["intent"] = "playback"
            
        # Try to detect part of day
        if any(word in text.lower() for word in ["morning", "காலை"]):
            result["part_of_day"] = "morning"
            
        # Set date to today by default
        today = date.today()
        result["date"] = today.isoformat()
        result["date_range_start"] = today.isoformat()
        result["date_range_end"] = today.isoformat()
    
    return result

def extract_with_transformer(text: str) -> Dict[str, Any]:
    # First try with regex for hyphenated time formats
    regex_result = extract_time_with_regex(text)
    if regex_result and "start_time" in regex_result and "end_time" in regex_result:
        print(f"Extracted with regex: {regex_result}")
        return regex_result
    
    # Otherwise try with the transformer model
    model, tokenizer = load_model()
    if not model or not tokenizer:
        return {}
    
    prompt = build_prompt(text)
    print(f"\nInput text: '{text}'")
    print(f"Generated prompt (truncated): '{prompt[:100]}...'")
    
    try:
        # Truncate if needed to avoid exceeding model's max length
        max_length = 512  # T5 default max length
        encoded = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=max_length)
        print(f"Encoded input length: {encoded.input_ids.shape[1]} tokens")
        
        if DEVICE != 'cpu':
            encoded = {k: v.to(DEVICE) for k,v in encoded.items()}
            
        print(f"Generating with max_new_tokens={MAX_NEW_TOKENS}...")
        output_ids = model.generate(**encoded, max_new_tokens=MAX_NEW_TOKENS, do_sample=False)
        decoded = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()
        print(f"Raw model output: '{decoded}'")
        
        # Extract first JSON object substring
        json_start = decoded.find('{')
        json_end = decoded.rfind('}')
        if json_start != -1 and json_end != -1 and json_end > json_start:
            candidate = decoded[json_start:json_end+1]
            print(f"Extracted JSON candidate: '{candidate}'")
        else:
            candidate = decoded
            print(f"No JSON found, using raw output: '{candidate}'")
        
        try:
            data = json.loads(candidate)
            # Basic post processing: coerce camera & times format if present
            if isinstance(data, dict):
                # Normalize times to HH:MM format
                for tkey in ['start_time','end_time']:
                    if tkey in data and isinstance(data[tkey], str):
                        time_str = data[tkey]
                        
                        # Handle HH:MM:SS format
                        parts = time_str.split(':')
                        if len(parts) >= 2:
                            data[tkey] = f"{parts[0].zfill(2)}:{parts[1].zfill(2)}"
                            continue
                            
                        # Handle H-M format (like "8-1" meaning "08:01")
                        if '-' in time_str and not ':' in time_str:
                            hour_min = time_str.split('-')
                            if len(hour_min) == 2:
                                try:
                                    hour = int(hour_min[0].strip())
                                    minute = int(hour_min[1].strip())
                                    # Only apply when minute part is small (likely just minutes, not another hour)
                                    if minute < 60:
                                        data[tkey] = f"{hour:02d}:{minute:02d}"
                                        continue
                                except ValueError:
                                    pass
                
                if 'camera' in data and isinstance(data['camera'], (int,str)):
                    try:
                        cam_int = int(str(data['camera']).strip())
                        data['camera'] = str(cam_int)
                    except Exception:
                        pass
                return data
        except Exception as e:
            print(f"JSON parsing error: {e}")
            # Fall back to regex if model fails
            regex_result = extract_time_with_regex(text)
            if regex_result:
                print(f"Falling back to regex result: {regex_result}")
                return regex_result
            return {}
    except Exception as gen_err:  # pragma: no cover
        print(f"[transformer_extractor] generation error: {gen_err}")
        # Fall back to regex if model fails
        regex_result = extract_time_with_regex(text)
        if regex_result:
            print(f"Falling back to regex result after error: {regex_result}")
            return regex_result
        return {}
    return {}
        try:
            data = json.loads(candidate)
            # Basic post processing: coerce camera & times format if present
            if isinstance(data, dict):
                # Normalize times to HH:MM format
                for tkey in ['start_time','end_time']:
                    if tkey in data and isinstance(data[tkey], str):
                        time_str = data[tkey]
                        
                        # Handle HH:MM:SS format
                        parts = time_str.split(':')
                        if len(parts) >= 2:
                            data[tkey] = f"{parts[0].zfill(2)}:{parts[1].zfill(2)}"
                            continue
                            
                        # Handle H-M format (like "8-1" meaning "08:01")
                        if '-' in time_str and not ':' in time_str:
                            hour_min = time_str.split('-')
                            if len(hour_min) == 2:
                                try:
                                    hour = int(hour_min[0].strip())
                                    minute = int(hour_min[1].strip())
                                    # Only apply when minute part is small (likely just minutes, not another hour)
                                    if minute < 60:
                                        data[tkey] = f"{hour:02d}:{minute:02d}"
                                        continue
                                except ValueError:
                                    pass
                if 'camera' in data and isinstance(data['camera'], (int,str)):
                    try:
                        cam_int = int(str(data['camera']).strip())
                        data['camera'] = str(cam_int)
                    except Exception:
                        pass
                return data
        except Exception:
            return {}
    except Exception as gen_err:  # pragma: no cover
        print(f"[transformer_extractor] generation error: {gen_err}")
        return {}
    return {}

if __name__ == "__main__":  # manual test
    print(extract_with_transformer("playback camera 4 yesterday from 11 pm to today 1 am"))
